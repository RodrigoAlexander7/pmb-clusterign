{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80eb7c9",
   "metadata": {},
   "source": [
    "# **Label every cluster with KeyBERT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ff219",
   "metadata": {},
   "source": [
    "### **1. Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92132d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\PROFESIONAL\\pmb-clusterign\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "# Level up one level directory to add app the the allowed routes\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from app.utils.base_dir import BASE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab24d2",
   "metadata": {},
   "source": [
    "### **2. Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d644305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed_model = SentenceTransformer(\"allenai/scibert_scivocab_uncased\")\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\") # using a mini model for performance\n",
    "kw_model = KeyBERT(model=embed_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d883f",
   "metadata": {},
   "source": [
    "### **3. Extract the keywords for cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7107116c",
   "metadata": {},
   "source": [
    "**3.1 Function to extract the keywords per cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe2f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def extract_keywords_keybert_clusterwise(\n",
    "        texts,  # the corpus of the cluster\n",
    "        top_n=10,       #number of keywords that return\n",
    "        keyphrase_ngram_range=(1,2),    # use bigrams\n",
    "        use_mmr=True,   # avoid redudant words\n",
    "        diversity=0.6,  # similitud and viriety\n",
    "        nr_candidates=20,\n",
    "        stop_words='english'\n",
    "    ):\n",
    "    \n",
    "    kws = kw_model.extract_keywords(texts,\n",
    "        keyphrase_ngram_range = keyphrase_ngram_range,\n",
    "        stop_words = stop_words,\n",
    "        top_n = top_n,\n",
    "        use_mmr = use_mmr,\n",
    "        diversity = diversity,\n",
    "        nr_candidates = nr_candidates)\n",
    "    # kws -> list of (keyword, score)\n",
    "    kws = [k for k,_ in kws]\n",
    "    gc.collect()\n",
    "    return kws\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c795a",
   "metadata": {},
   "source": [
    "**3.2 Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345a278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clean_data_path = BASE_DIR/'data'/'processed'/'noCleanProcessedData.json' \n",
    "clusters_path = BASE_DIR/'data'/'processed'/'clusters.json' \n",
    "\n",
    "no_clean_data_array = []\n",
    "no_clean_data = {}\n",
    "clusters = {}\n",
    "with open(no_clean_data_path, 'r') as f:\n",
    "    no_clean_data_array = json.load(f)\n",
    "\n",
    "with open(clusters_path, 'r') as f:\n",
    "    clusters = json.load(f)\n",
    "\n",
    "def parse_to_dict(data:list):\n",
    "    for element in data:\n",
    "        for k, v in element.items():\n",
    "            no_clean_data[k] = v\n",
    "parse_to_dict(no_clean_data_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf6eb4",
   "metadata": {},
   "source": [
    "**3.3 Get cluster corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cde0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like {11 : [\"text 01\", \"text 02\"]}\n",
    "clusterNumber_corpusText = defaultdict(str)\n",
    "MAX_DOCS = 4 # total 5 cause i start in 0\n",
    "\n",
    "for cluster_number, titles_list in clusters.items():\n",
    "    for i, title in enumerate(titles_list):\n",
    "        i+=1\n",
    "        if i <= MAX_DOCS:\n",
    "            clusterNumber_corpusText[cluster_number] += no_clean_data[title]\n",
    "        else: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1534ec6",
   "metadata": {},
   "source": [
    "**3.2 Extract keywords for all custer's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords():\n",
    "    response = {} # is a dict with {number_cluster:[keyword01, keyword02,...]}\n",
    "    for c_number, list_text in clusterNumber_corpusText.items():\n",
    "        kwrds = extract_keywords_keybert_clusterwise(list_text)\n",
    "        response[c_number] = kwrds \n",
    "    return response\n",
    "\n",
    "res = extract_keywords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8584c",
   "metadata": {},
   "source": [
    "**3.3 Export to Json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(res)\n",
    "kwr_path = BASE_DIR/'data'/'processed'/'keywords.json' \n",
    "with open(kwr_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(res, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
